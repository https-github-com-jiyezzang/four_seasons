{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5016afcb",
   "metadata": {},
   "source": [
    "## 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5f21d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.9/site-packages (3.36.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from gradio) (8.3.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from gradio) (1.3.3)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: gradio-client>=0.2.7 in /opt/conda/lib/python3.9/site-packages (from gradio) (0.2.7)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: semantic-version in /opt/conda/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.9/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.9/site-packages (from gradio) (0.100.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.9/site-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.9/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.9/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from gradio) (1.21.4)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.9/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from gradio) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.9/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.9/site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from gradio) (3.4.3)\n",
      "Requirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.9/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.2.1)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from gradio-client>=0.2.7->gradio) (2021.11.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from gradio-client>=0.2.7->gradio) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.14.0->gradio) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.14.0->gradio) (4.62.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->gradio) (2021.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio) (8.0.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (2.0.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.9/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic->gradio) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.1.2 in /opt/conda/lib/python3.9/site-packages (from pydantic->gradio) (2.1.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (2021.10.8)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (0.9.1)\n",
      "Requirement already satisfied: chardet==3.* in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (3.0.4)\n",
      "Requirement already satisfied: hstspreload in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (2021.12.1)\n",
      "Requirement already satisfied: idna==2.* in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (2.10)\n",
      "Requirement already satisfied: h2==3.* in /opt/conda/lib/python3.9/site-packages (from httpcore==0.9.*->httpx->gradio) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.9/site-packages (from h2==3.*->httpcore==0.9.*->httpx->gradio) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.9/site-packages (from h2==3.*->httpcore==0.9.*->httpx->gradio) (3.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->gradio) (1.26.7)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.9/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from starlette<0.28.0,>=0.27.0->fastapi->gradio) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91933702",
   "metadata": {},
   "source": [
    "# gradio 구현(1) : Hello!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c13a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:700\n",
      "Running on public URL: https://42345c90e8bf720163.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://42345c90e8bf720163.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet,\n",
    "                    allow_flagging='manual',\n",
    "                    inputs = \"text\",\n",
    "                    outputs = \"text\")\n",
    "\n",
    "demo.launch(server_name = \"0.0.0.0\",\n",
    "            server_port = 700,\n",
    "            auth = (\"noname\", \"passwdl\"),\n",
    "            share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e20d8",
   "metadata": {},
   "source": [
    "- launch()에서 share=True로 지정하면 gradio에서 제공하는 소스를 사용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b1ff1",
   "metadata": {},
   "source": [
    "# gradio 구현(2) : 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46195a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "14540800/14536120 [==============================] - 0s 0us/step\n",
      "14548992/14536120 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inception_net = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e2773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "def classify_image(inp):\n",
    "    inp = inp.reshape((-1, 224, 224, 3))\n",
    "    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    prediction = inception_net.predict(inp).flatten()\n",
    "    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "    return confidences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91fd3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:600\n",
      "Running on public URL: https://d7fcaa8cb3ba1bafc9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d7fcaa8cb3ba1bafc9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_31/564398416.py\", line 13, in classify_image\n",
      "    image = image.reshape((1, 32 * 32 * 3)) / 255.0\n",
      "ValueError: cannot reshape array of size 150528 into shape (1,3072)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/routes.py\", line 439, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1384, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/blocks.py\", line 1089, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gradio/utils.py\", line 700, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_31/564398416.py\", line 13, in classify_image\n",
      "    image = image.reshape((1, 32 * 32 * 3)) / 255.0\n",
      "ValueError: cannot reshape array of size 150528 into shape (1,3072)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "classification = gr.Interface(fn=classify_image,\n",
    "                              inputs = gr.Image(shape=(224,224)),\n",
    "                              outputs = gr.Label(num_top_classes=3))\n",
    "\n",
    "classification.launch(server_name = \"0.0.0.0\",\n",
    "                      server_port = 600,\n",
    "                      auth = (\"noname\", \"passwdl\"),\n",
    "                      share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a44baba",
   "metadata": {},
   "source": [
    "# 퍼스널 컬러 앱 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn / zero shot의 경우\n",
    "\n",
    "## 1. 데이터 수집(라벨링 된)\n",
    "## 2. 데이터 입력\n",
    "## 3. 모델이 웜/쿨인지 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81c189fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "74/74 [==============================] - 3s 24ms/step - loss: 2.4594 - accuracy: 0.2381 - val_loss: 8.2493 - val_accuracy: 0.1582\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 2.0836 - accuracy: 0.3036 - val_loss: 3.5494 - val_accuracy: 0.1947\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.8880 - accuracy: 0.3479 - val_loss: 2.6983 - val_accuracy: 0.2472\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.7694 - accuracy: 0.3812 - val_loss: 1.8561 - val_accuracy: 0.3471\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.6973 - accuracy: 0.4047 - val_loss: 1.7415 - val_accuracy: 0.3750\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.6479 - accuracy: 0.4222 - val_loss: 1.7117 - val_accuracy: 0.3881\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.6072 - accuracy: 0.4298 - val_loss: 1.7970 - val_accuracy: 0.3489\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5863 - accuracy: 0.4401 - val_loss: 1.7305 - val_accuracy: 0.3866\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5634 - accuracy: 0.4468 - val_loss: 1.7100 - val_accuracy: 0.3930\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 1.5520 - accuracy: 0.4509 - val_loss: 1.6958 - val_accuracy: 0.4158\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5401 - accuracy: 0.4527 - val_loss: 1.7436 - val_accuracy: 0.4035\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5259 - accuracy: 0.4596 - val_loss: 1.6961 - val_accuracy: 0.4093\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5106 - accuracy: 0.4644 - val_loss: 1.6211 - val_accuracy: 0.4242\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.5064 - accuracy: 0.4669 - val_loss: 1.6958 - val_accuracy: 0.4069\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.4974 - accuracy: 0.4704 - val_loss: 1.7211 - val_accuracy: 0.4430\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 1.4918 - accuracy: 0.4722 - val_loss: 1.7038 - val_accuracy: 0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/564398416.py:85: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Image(shape=(32, 32)),\n",
      "/tmp/ipykernel_31/564398416.py:85: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Image(shape=(32, 32)),\n",
      "/tmp/ipykernel_31/564398416.py:86: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs=gr.outputs.Label(num_top_classes=3))\n",
      "/tmp/ipykernel_31/564398416.py:86: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
      "  outputs=gr.outputs.Label(num_top_classes=3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:300\n",
      "Running on public URL: https://29dc69126715bd74ee.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://29dc69126715bd74ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cifar10으로 예상 모형 만들기\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def classify_image(image):\n",
    "    # Preprocess the image\n",
    "    image = image.reshape((1, 32 * 32 * 3)) / 255.0\n",
    "\n",
    "    # Load the trained model\n",
    "    model = keras.models.load_model('keras_cifar10_model.h5')\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(image)\n",
    "    class_index = np.argmax(prediction)\n",
    "    class_name = class_names[class_index]\n",
    "\n",
    "    return class_name\n",
    "\n",
    "# Load CIFAR-10 dataset and split into train, validation, and test sets\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full,\n",
    "                                                  y_train_full,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=42)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(x_train.shape[0], 32 * 32 * 3)\n",
    "x_val = x_val.reshape(x_val.shape[0], 32 * 32 * 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32 * 32 * 3)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_val = x_val / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Input(shape=(3072,)))\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax', name='output'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "check_point_cb = callbacks.ModelCheckpoint('keras_cifar10_model.h5', save_best_only=True)\n",
    "early_stopping_cb = callbacks.EarlyStopping(patience=3,\n",
    "                                            monitor='val_loss',\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[check_point_cb, early_stopping_cb])\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(fn=classify_image,\n",
    "                     inputs=gr.inputs.Image(shape=(32, 32)),\n",
    "                     outputs=gr.outputs.Label(num_top_classes=2))\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True,\n",
    "             server_name = \"0.0.0.0\",\n",
    "             server_port = 300,\n",
    "             auth = (\"noname\", \"passwdl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f4aab",
   "metadata": {},
   "source": [
    "- 위에서는 cifar10의 딥러닝 학습 분류 모델을 이용한 것을 gradio로 구현한 코드이다.\n",
    "    퍼스널 컬러 분류 코드가 만들어지면 위와 같이 구현할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c1e70",
   "metadata": {},
   "source": [
    "- 퍼스널 컬러의(구현한다면) 퍼센테이지(%)를 확인할 수 있게 하기 위해 label의 top2를 나타내게 하고 싶은데 데모에선 됐는데 위에선 표시가 안 됐다. 다시 코드를 살펴보고 수정해야 할 것 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5876083",
   "metadata": {},
   "source": [
    "## 퍼컬 앱 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼스널 컬러 분류 함수 만들기\n",
    "\n",
    "def personal_color(img):\n",
    "    img = img.reshape((-1, 244, 244, 3))\n",
    "#     model = keras.models.load_model('unet_model.h5')\n",
    "#     segmentation = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio로 시각화? 웹 구현\n",
    "import gradio as gr\n",
    "\n",
    "classification = gr.Interface(fn=personal_color,\n",
    "                              inputs=\"image\",\n",
    "                              outputs=\"label\",\n",
    "                              examples = [])\n",
    "\n",
    "classification.launch(share=True,\n",
    "                      server_name = \"0.0.0.0\",\n",
    "                      server_port = 8088,\n",
    "                      auth = (\"noname\", \"passwdl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26574cc3",
   "metadata": {},
   "source": [
    "- 위는 아직 퍼스널 컬러 코드가 완성되지 않아 비워두었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ed55a",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- 분류 모델 공식 홈페이지 데모 버전 (https://www.gradio.app/guides/image-classification-in-tensorflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
