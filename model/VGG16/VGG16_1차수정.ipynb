{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZwsAoPOlKD1W",
        "ETU0Hu45KHYb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트: 퍼스널 컬러 진단 - VGG16\n",
        "\n",
        "## 목차\n",
        "1. ImageNet으로 사전 학습된 VGG16  \n",
        "참고 링크: https://han-py.tistory.com/213  \n",
        "2. Custom VGG16 (미완성)\n",
        "3. VGG16에 퍼스널컬러(웜/쿨) 적용하기\n",
        "참고 링크:https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=dnjswns2280&logNo=221738517884  "
      ],
      "metadata": {
        "id": "8AVfKtODAaL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ImageNet으로 사전 학습된 VGG16"
      ],
      "metadata": {
        "id": "ZwsAoPOlKD1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "UDiaXdEWAPhU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array # 오류 발생시 tensorflow 재설치하고 런타임 재연결 추천\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from IPython.display import display # 이미지 출력 함수"
      ],
      "metadata": {
        "id": "Jzu62BvtCHZ1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fZ5brIx5AKPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d539b697-97da-4b36-b2d6-ed81d3c5e57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 3s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# VGG16 모델 불러오기\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# 모델의 모양을 보여준다.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_vgg16(model, filename) :\n",
        "\n",
        "  # 이미지 파일을 읽고 화면에 표시\n",
        "  image = load_img(filename)\n",
        "  # image = PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=688x550\n",
        "  display(image)\n",
        "\n",
        "\n",
        "  # 모델 사이즈로 이미지 파일을 읽기\n",
        "  image = load_img(filename, target_size=(224, 224))\n",
        "  # image = PIL.Image.Image image mode=RGB size=224x224\n",
        "\n",
        "\n",
        "  # 이미지 데이터를 numpy로 변환\n",
        "  image = img_to_array(image)\n",
        "  # image.shape = (224, 224, 3)\n",
        "\n",
        "  # vgg16.preprocess_input()을 호출하기 위해 차원을 조정\n",
        "  # 보통 모델을 여러 이미지를 한번에 호출.\n",
        "  # 맨 앞의 1 : 이미지 갯수가 1개라는 것.\n",
        "  # 두번째 224 : 가로\n",
        "  # 세번째 224 : 세로\n",
        "  # 네번째 3 : R, G, B 3개\n",
        "  image = image.reshape((1, 224, 224, 3))\n",
        "\n",
        "  # VGG16 모델 호출을 위해 데이터 전처리.\n",
        "  # -255 ~ 255 사이 값으로 정규화한다.\n",
        "  # 그리고 RGB를 BGR순으로 바꾼다.\n",
        "  image = vgg16.preprocess_input(image)\n",
        "\n",
        "\n",
        "  # 이미지를 모델에 적용\n",
        "  yhat = model.predict(image)\n",
        "  # yhat = [[2.03485320e-06 4.21382174e-06 1.45730738e-07 1.04057870e-06\n",
        "  #          6.61934010e-08 2.63145339e-04 4.49358195e-05 2.03222541e-08\n",
        "  #          ... ]] # 1000개 클래스에 대한 결과값.\n",
        "  #\n",
        "\n",
        "\n",
        "  # 모델 적용된 결과를 파싱\n",
        "  label = vgg16.decode_predictions(yhat)\n",
        "  # label = [[('n02655020', 'puffer', 0.9612253), ... ]]\n",
        "\n",
        "  # 가장 확률이 높은 결과를 획득\n",
        "  label = label[0][0]\n",
        "  # label = ('n02655020', 'puffer', 0.9612253)\n",
        "\n",
        "  # 라벨과 라벨을 예측한 확률을 출력\n",
        "  print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "metadata": {
        "id": "PyHz3zAcBBh0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04bCBy2WAS0X",
        "outputId": "cb9ad60d-4ace-4743-cc94-00a520ffafc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사진 경로\n",
        "files = [\n",
        "    \"/content/drive/MyDrive/four_seasons/데이터셋_jpg/고양이/고양이.jpg\",\n",
        "    \"/content/drive/MyDrive/four_seasons/데이터셋_jpg/고양이/고양이2.jpg\",\n",
        "    \"/content/drive/MyDrive/four_seasons/데이터셋_jpg/웜톤/웜톤_jpg/리사.jpg\",\n",
        "    \"/content/drive/MyDrive/four_seasons/데이터셋_jpg/쿨톤/쿨톤_jpg/김고은.jpg\"\n",
        "]"
      ],
      "metadata": {
        "id": "rU8qBsXAHAGz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 사진마다 예측된 라벨과 예측한 확률 확인하기\n",
        "for file in files :\n",
        "  predict_vgg16(model, file)"
      ],
      "metadata": {
        "id": "DgSvxOaBBoCs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "fe36c715-4cc1-4900-8ff3-452e6bef69ea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/four_seasons/데이터셋_jpg/고양이/고양이.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 561ms/step\n",
            "Egyptian_cat (48.11%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/four_seasons/데이터셋_jpg/고양이/고양이2.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 585ms/step\n",
            "tabby (37.17%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/four_seasons/데이터셋_jpg/웜톤/웜톤_jpg/리사.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 536ms/step\n",
            "sweatshirt (38.55%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/four_seasons/데이터셋_jpg/쿨톤/쿨톤_jpg/김고은.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 541ms/step\n",
            "pajama (15.46%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Custom VGG16\n",
        "- 미완성. fit부분이 맞지 않음"
      ],
      "metadata": {
        "id": "ETU0Hu45KHYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "def build_vgg_block(input_layer,\n",
        "                    num_cnn=3,\n",
        "                    channel=64,\n",
        "                    block_num=1,\n",
        "                   ):\n",
        "    # 입력 레이어\n",
        "    x = input_layer\n",
        "\t# num_cnn : 한블럭에서 사용할 conv필터 개수 네트워크에 따라 2개일때가 있고 3개일때가 있음.\n",
        "    # CNN 레이어\n",
        "    for cnn_num in range(num_cnn):\n",
        "        x = keras.layers.Conv2D(\n",
        "            filters=channel,\n",
        "            kernel_size=(3,3),\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            padding='same',\n",
        "            name=f'block{block_num}_conv{cnn_num}'\n",
        "        )(x)\n",
        "\n",
        "    # Max Pooling 레이어\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=2,\n",
        "        name=f'block{block_num}_pooling'\n",
        "    )(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "WzReVw4uF6Nq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg(input_shape=(32,32,3),\n",
        "              num_cnn_list=[2,2,3,3,3],\n",
        "              channel_list=[64,128,256,512,512],\n",
        "              num_classes=10):\n",
        "\n",
        "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
        "    output = input_layer\n",
        "\n",
        "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
        "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
        "        output = build_vgg_block(\n",
        "            output,\n",
        "            num_cnn=num_cnn,\n",
        "            channel=channel,\n",
        "            block_num=i\n",
        "        )\n",
        "\n",
        "    output = keras.layers.Flatten(name='flatten')(output)\n",
        "    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\n",
        "    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\n",
        "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=input_layer,\n",
        "        outputs=output\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "mw15zMgOKqag"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg_19 = build_vgg(\n",
        "#     num_cnn_list=[2,2,4,4,4],\n",
        "#     channel_list=[64,128,256,512,512]\n",
        "# )"
      ],
      "metadata": {
        "id": "187NXZ9wLwHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16 = build_vgg()"
      ],
      "metadata": {
        "id": "k5uDtU1EKzo9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCH = 20"
      ],
      "metadata": {
        "id": "0xfnsfXRL9Pv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# 데이터 정규화 (0~1 사이 값으로 스케일링)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# 레이블을 One-Hot 인코딩\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBxN71ySQPga",
        "outputId": "9d554504-0388-440a-c3a4-73c6d6689d24"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_16.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# history_16 = vgg_16.fit(\n",
        "#     x_train,\n",
        "#     epochs=EPOCH,\n",
        "#     validation_data=x_test,\n",
        "#     verbose=1,\n",
        "#     use_multiprocessing=True,\n",
        "# )\n",
        "history_16 = vgg_16.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=EPOCH,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6N--Hf7EK9CP",
        "outputId": "38d5b260-4e3c-4106-aae4-870036aef636"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5975cabadad1>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history_16 = vgg_16.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-43-5975cabadad1>\", line 14, in <cell line: 14>\n      history_16 = vgg_16.fit(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [32,10] and labels shape [320]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_5512]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. VGG16에 퍼스널컬러(웜/쿨) 적용하기"
      ],
      "metadata": {
        "id": "tcNgW3nCANSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 라이브러리 및 데이터 불러오기"
      ],
      "metadata": {
        "id": "QKkxomUDLD7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "1ryUcA_jHSbt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdt8vj5FHShw",
        "outputId": "526394e2-d273-4cd8-f9ed-bb537694f46f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 불러오는 함수\n",
        "def load_images_from_directory(directory_path):\n",
        "    image_paths = glob.glob(directory_path + '/*.jpg')  # 디렉토리 내의 모든 jpg 파일 경로 찾기\n",
        "    image_paths.extend(glob.glob(directory_path + '/*.jpeg'))  # 디렉토리 내의 모든 jpeg 파일 경로 추가\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path)\n",
        "        image_np = np.array(image)\n",
        "        images.append(image_np)\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "heINaLWoJy2y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 이미지 불러오기\n",
        "directory_path = \"/content/drive/MyDrive/four_seasons/사계절_연예인 이미지 데이터셋/prototype/웜톤_jpg\"  # 디렉토리 경로\n",
        "directory_path2 = \"/content/drive/MyDrive/four_seasons/사계절_연예인 이미지 데이터셋/prototype/쿨톤_jpg\"  # 디렉토리 경로\n",
        "images = load_images_from_directory(directory_path)\n",
        "images2 = load_images_from_directory(directory_path2)\n",
        "\n",
        "length = len(images)\n",
        "print(length)\n",
        "print(len(images2))\n",
        "\n",
        "# 이미지 리스트 합치기\n",
        "images = np.concatenate((images, images2), axis=0)\n",
        "print(len(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHhobsDKHSlU",
        "outputId": "baf0e3ac-e044-4fba-df8e-25c472a8437e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n",
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) 데이터 전처리"
      ],
      "metadata": {
        "id": "JuqZO6xjLPEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    # 이미지 크기 조절\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    # 이미지를 [0, 1] 범위로 정규화\n",
        "    image = image / 255.0\n",
        "    return image\n",
        "\n",
        "images = np.array([preprocess_image(image) for image in images])\n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nduCOt1YHSoj",
        "outputId": "b9c21304-a6c6-4641-f3da-3cdc44046328"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels에 대한 코드\n",
        "num = len(images)\n",
        "labels = np.zeros(num)\n",
        "\n",
        "# 뒤쪽의 50개의 요소를 1로 변경\n",
        "labels[length:] = 1\n",
        "\n",
        "# 0이 웜톤 1이 쿨톤\n",
        "print(len(images))\n",
        "print(labels.shape)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2coAcsEHSrR",
        "outputId": "b8ce40fa-f22a-405f-99ec-5a2d616f2f00"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "(100,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) train, val 분리하기"
      ],
      "metadata": {
        "id": "dbzMvdvQLR45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(images,\n",
        "                                                  labels,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=1024)\n",
        "\n",
        "print(\"x_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"x_val: \", x_val.shape)\n",
        "print(\"y_val: \", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyOgLqgEIidF",
        "outputId": "18cf4f86-ac22-45b3-de2a-e03edc83a971"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train:  (70, 224, 224, 3)\n",
            "y_train:  (70,)\n",
            "x_val:  (30, 224, 224, 3)\n",
            "y_val:  (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 텐서로 변환\n",
        "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
        "x_val = tf.convert_to_tensor(x_val, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "60cskZPQIif3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) 모델 정의 및 컴파일"
      ],
      "metadata": {
        "id": "7dzDlNR0LViM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 모델 불러오기\n",
        "vgg16_model = vgg16.VGG16()\n",
        "\n",
        "# 추가하기\n",
        "model = models.Sequential()\n",
        "model.add(vgg16_model)\n",
        "model.add(layers.Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "QK2JsubkIiiP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "7TeFqbJ-Iiky"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5) 모델 학습하기"
      ],
      "metadata": {
        "id": "cgKOImX7LZSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7분걸림\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=2,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJRmMrcwASla",
        "outputId": "a8cb0384-ec19-4008-d07d-aeefd60ffed6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2/2 [==============================] - 207s 39s/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.7007 - val_accuracy: 0.4000\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 216s 59s/step - loss: 0.6908 - accuracy: 0.5429 - val_loss: 0.7010 - val_accuracy: 0.4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) 예측하기"
      ],
      "metadata": {
        "id": "eMj_vDU5LgcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_val)\n",
        "pred_class = np.argmax(pred, axis=1)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUB92j00ATI6",
        "outputId": "03de6b37-0106-4470-f848-af73a7869137"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 20s 20s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_class)\n",
        "print(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtr35C-CATKt",
        "outputId": "8dd8d144-26b0-4f7c-b53a-bd76f51974c7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(pred_class == y_val)\n",
        "print('accuracy: %f' % (acc,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ui06FtGATM_",
        "outputId": "a5dfb3ad-2402-415d-bc4e-9411a0a7afbc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7) TEST"
      ],
      "metadata": {
        "id": "z-sJuwJKLjJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = [\"웜톤\", \"쿨톤\"]"
      ],
      "metadata": {
        "id": "8cNAWpvBATPM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 불러오기 (낱개 버전)\n",
        "test_path = \"/content/drive/MyDrive/four_seasons/사계절_연예인 이미지 데이터셋/prototype/연예인 사진 10장/01.jpg\"\n",
        "x_test = Image.open(test_path)\n",
        "x_test = np.array(x_test)\n",
        "print(x_test.shape)\n",
        "\n",
        "# 배열의 크기 변환\n",
        "x_test = x_test.reshape((1, x_test.shape[0], x_test.shape[1], 3))\n",
        "print(\"변환된 배열 크기:\", x_test.shape)\n",
        "\n",
        "# 전처리(resize, 정규화)\n",
        "x_test = preprocess_image(x_test)\n",
        "print(x_test.shape)\n",
        "\n",
        "# 만약 앱구현과 연결된다면 저장된 모델을 다시 돌릴 필요없이 저장된 최적의 모델을 사용하도록 수정해야함\n",
        "# test\n",
        "pred = model.predict(x_test)\n",
        "pred_class = np.argmax(pred, axis=1)\n",
        "print(\"당신은\", class_name[int(pred_class)], \"입니다~!\")\n",
        "print(\"웜톤일 확률: \", np.round(pred[:, 0], 3))\n",
        "print(\"쿨톤일 확률: \", np.round(pred[:, 1], 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG_fD_tAATRn",
        "outputId": "330b5d35-d89e-409b-e816-bab63c4a5480"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600, 3)\n",
            "변환된 배열 크기: (1, 600, 600, 3)\n",
            "(1, 224, 224, 3)\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "당신은 쿨톤 입니다~!\n",
            "웜톤일 확률:  [0.482]\n",
            "쿨톤일 확률:  [0.518]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아이유는 웜톤이다ㅠ"
      ],
      "metadata": {
        "id": "a4hWOcheATT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
