{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OWk6DIEDU218"
      },
      "id": "OWk6DIEDU218",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5016afcb",
      "metadata": {
        "id": "5016afcb"
      },
      "source": [
        "## 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e5f21d6",
      "metadata": {
        "scrolled": true,
        "id": "8e5f21d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e0b3a5-108d-448b-e536-f90787c8090e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-3.36.1-py3-none-any.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.7 (from gradio)\n",
            "  Downloading gradio_client-0.2.8-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.11)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.4)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.5.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.16)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=163aa686b846f4712fa3bfd5ff7d99fb7a02ae48884f6dd55430adc7f61b30cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, markdown-it-py, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.100.0 ffmpy-0.3.0 gradio-3.36.1 gradio-client-0.2.8 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 orjson-3.9.2 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91933702",
      "metadata": {
        "id": "91933702"
      },
      "source": [
        "# gradio 구현(1) : Hello!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c13a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "d6c13a98",
        "outputId": "42848e92-0782-4697-d32a-896768fbeb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://90ed355a55a23d122a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://90ed355a55a23d122a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet,\n",
        "                    allow_flagging='manual',\n",
        "                    inputs = \"text\",\n",
        "                    outputs = \"text\")\n",
        "\n",
        "demo.launch(server_name = \"0.0.0.0\",\n",
        "            server_port = 700,\n",
        "            # auth = (\"noname\", \"passwdl\"),\n",
        "            share=True\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676e20d8",
      "metadata": {
        "id": "676e20d8"
      },
      "source": [
        "- launch()에서 share=True로 지정하면 gradio에서 제공하는 소스를 사용하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0b1ff1",
      "metadata": {
        "id": "dd0b1ff1"
      },
      "source": [
        "# gradio 구현(2) : 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46195a40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46195a40",
        "outputId": "7715cc8e-648e-4d65-b980-748f006b93b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inception_net = tf.keras.applications.MobileNetV2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e2773f",
      "metadata": {
        "id": "e8e2773f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"https://git.io/JJkYN\")\n",
        "labels = response.text.split(\"\\n\")\n",
        "\n",
        "def classify_image(inp):\n",
        "    inp = inp.reshape((-1, 224, 224, 3))\n",
        "    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
        "    prediction = inception_net.predict(inp).flatten()\n",
        "    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
        "    return confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91fd3dd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "91fd3dd0",
        "outputId": "76bac3b4-2dd8-468d-ec03-eca99fa34452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9297d34693bc8cc930.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9297d34693bc8cc930.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "classification = gr.Interface(fn=classify_image,\n",
        "                              inputs = gr.Image(shape=(224,224)),\n",
        "                              outputs = gr.Label(num_top_classes=3))\n",
        "\n",
        "classification.launch(share=True,\n",
        "                      server_name = \"0.0.0.0\",\n",
        "                      server_port = 600\n",
        "                      # auth = (\"noname\", \"passwdl\"),\n",
        "                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a44baba",
      "metadata": {
        "id": "8a44baba"
      },
      "source": [
        "# 1. 퍼스널 컬러 앱 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cifar10으로 시험 코드"
      ],
      "metadata": {
        "id": "4Pgi1ut117xB"
      },
      "id": "4Pgi1ut117xB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fca5875",
      "metadata": {
        "id": "5fca5875"
      },
      "outputs": [],
      "source": [
        "# knn / zero shot의 경우\n",
        "\n",
        "## 1. 데이터 수집(라벨링 된)\n",
        "## 2. 데이터 입력\n",
        "## 3. 모델이 웜/쿨인지 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c189fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c189fb",
        "outputId": "2da5bbb5-0712-4668-fb03-29394e6f5cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/40\n",
            "74/74 [==============================] - 36s 473ms/step - loss: 2.4578 - accuracy: 0.2354 - val_loss: 6.6257 - val_accuracy: 0.1426\n",
            "Epoch 2/40\n",
            "74/74 [==============================] - 35s 468ms/step - loss: 2.0762 - accuracy: 0.3089 - val_loss: 3.5605 - val_accuracy: 0.2335\n",
            "Epoch 3/40\n",
            "74/74 [==============================] - 35s 471ms/step - loss: 1.9017 - accuracy: 0.3467 - val_loss: 1.9820 - val_accuracy: 0.3050\n",
            "Epoch 4/40\n",
            "74/74 [==============================] - 35s 470ms/step - loss: 1.7887 - accuracy: 0.3739 - val_loss: 1.8091 - val_accuracy: 0.3538\n",
            "Epoch 5/40\n",
            "74/74 [==============================] - 32s 439ms/step - loss: 1.7203 - accuracy: 0.3960 - val_loss: 1.7812 - val_accuracy: 0.3682\n",
            "Epoch 6/40\n",
            "74/74 [==============================] - 34s 454ms/step - loss: 1.6731 - accuracy: 0.4113 - val_loss: 1.7431 - val_accuracy: 0.3920\n",
            "Epoch 7/40\n",
            "74/74 [==============================] - 33s 444ms/step - loss: 1.6345 - accuracy: 0.4222 - val_loss: 1.8034 - val_accuracy: 0.3747\n",
            "Epoch 8/40\n",
            "74/74 [==============================] - 34s 457ms/step - loss: 1.6162 - accuracy: 0.4283 - val_loss: 1.6994 - val_accuracy: 0.3861\n",
            "Epoch 9/40\n",
            "74/74 [==============================] - 33s 447ms/step - loss: 1.5947 - accuracy: 0.4366 - val_loss: 1.7607 - val_accuracy: 0.3996\n",
            "Epoch 10/40\n",
            "74/74 [==============================] - 32s 434ms/step - loss: 1.5756 - accuracy: 0.4390 - val_loss: 1.6721 - val_accuracy: 0.4148\n",
            "Epoch 11/40\n",
            "74/74 [==============================] - 33s 452ms/step - loss: 1.5675 - accuracy: 0.4438 - val_loss: 1.6770 - val_accuracy: 0.4204\n",
            "Epoch 12/40\n",
            "74/74 [==============================] - 35s 472ms/step - loss: 1.5656 - accuracy: 0.4431 - val_loss: 1.6937 - val_accuracy: 0.3956\n",
            "Epoch 13/40\n",
            "74/74 [==============================] - 33s 454ms/step - loss: 1.5621 - accuracy: 0.4446 - val_loss: 1.6818 - val_accuracy: 0.4018\n"
          ]
        }
      ],
      "source": [
        "# cifar10으로 예상 모형 만들기\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def classify_image(image):\n",
        "    # Preprocess the image\n",
        "    image = image.reshape((1, 32 * 32 * 3)) / 255.0\n",
        "\n",
        "    # Load the trained model\n",
        "    model = keras.models.load_model('keras_cifar10_model.h5')\n",
        "\n",
        "    # Perform prediction\n",
        "    prediction = model.predict(image)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_name = class_names[class_index]\n",
        "\n",
        "    return class_name\n",
        "\n",
        "# Load CIFAR-10 dataset and split into train, validation, and test sets\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full,\n",
        "                                                  y_train_full,\n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=42)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 32 * 32 * 3)\n",
        "x_val = x_val.reshape(x_val.shape[0], 32 * 32 * 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32 * 32 * 3)\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_val = x_val / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Input(shape=(3072,)))\n",
        "model.add(layers.Dense(2048, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "check_point_cb = callbacks.ModelCheckpoint('keras_cifar10_model.h5', save_best_only=True)\n",
        "early_stopping_cb = callbacks.EarlyStopping(patience=3,\n",
        "                                            monitor='val_loss',\n",
        "                                            restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=[check_point_cb, early_stopping_cb])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "iface = gr.Interface(fn=classify_image,\n",
        "                     inputs=gr.inputs.Image(shape=(32, 32)),\n",
        "                     outputs=gr.outputs.Label(num_top_classes=2))\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True,\n",
        "             server_name = \"0.0.0.0\",\n",
        "             server_port = 300)\n",
        "            #  auth = (\"noname\", \"passwdl\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "FaQMCTP7yMHg",
        "outputId": "83b218aa-d117-4cde-eb9f-67df9b7447b3"
      },
      "id": "FaQMCTP7yMHg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-efccfe3798c5>:3: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Image(shape=(32, 32)),\n",
            "<ipython-input-8-efccfe3798c5>:3: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Image(shape=(32, 32)),\n",
            "<ipython-input-8-efccfe3798c5>:4: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n",
            "<ipython-input-8-efccfe3798c5>:4: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0950c8587530685a44.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0950c8587530685a44.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f6f4aab",
      "metadata": {
        "id": "8f6f4aab"
      },
      "source": [
        "- 위에서는 cifar10의 딥러닝 학습 분류 모델을 이용한 것을 gradio로 구현한 코드이다.\n",
        "    퍼스널 컬러 분류 코드가 만들어지면 위와 같이 구현할 수 있을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "553c1e70",
      "metadata": {
        "id": "553c1e70"
      },
      "source": [
        "- 퍼스널 컬러의(구현한다면) 퍼센테이지(%)를 확인할 수 있게 하기 위해 label의 top2를 나타내게 하고 싶은데 데모에선 됐는데 위에선 표시가 안 됐다. 다시 코드를 살펴보고 수정해야 할 것 같음"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5876083",
      "metadata": {
        "id": "f5876083"
      },
      "source": [
        "## KNN 적용 퍼컬 앱 구현(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 블러오기\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "jlnqXtRI2I5b"
      },
      "id": "jlnqXtRI2I5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "def load_images_from_directory(directory_path):\n",
        "    image_paths = glob.glob(directory_path + '/*.jpg')  # 디렉토리 내의 모든 jpg 파일 경로 찾기\n",
        "    image_paths.extend(glob.glob(directory_path + '/*.jpeg'))\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path)\n",
        "        image_np = np.array(image)\n",
        "        images.append(image_np)\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "6z8G1UMV2TZd"
      },
      "id": "6z8G1UMV2TZd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜\n",
        "\n",
        "# !unzip -qq \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Four_seasons/사계절_연예인 이미지 데이터셋/prototype/웜톤/웜톤_jpg.zip\""
      ],
      "metadata": {
        "id": "xStbZGCwCOQo"
      },
      "id": "xStbZGCwCOQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/쿨\n",
        "\n",
        "# !unzip -qq \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Four_seasons/사계절_연예인 이미지 데이터셋/prototype/쿨톤/쿨톤_jpg.zip\""
      ],
      "metadata": {
        "id": "lXP6a5wcCy4V"
      },
      "id": "lXP6a5wcCy4V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 이미지 불러오기\n",
        "directory_path = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/쿨\"  # 디렉토리 경로\n",
        "directory_path2 = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜\"  # 디렉토리 경로\n",
        "images = load_images_from_directory(directory_path)\n",
        "images2 = load_images_from_directory(directory_path2)\n",
        "\n",
        "length = len(images)\n",
        "print(length)\n",
        "print(len(images2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJlVTs4M2TTI",
        "outputId": "9454d844-3a84-4516-d092-37de95100a95"
      },
      "id": "OJlVTs4M2TTI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 리스트 합치기\n",
        "\n",
        "images = np.concatenate((images, images2), axis=0)\n",
        "print(len(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9M1l52ZDVJ2",
        "outputId": "47784d75-0032-4019-e82e-da95171156a3"
      },
      "id": "y9M1l52ZDVJ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# 새로운 크기로 리사이즈할 이미지의 너비와 높이\n",
        "new_width = 200\n",
        "new_height = 200\n",
        "\n",
        "resized_images = []\n",
        "for image in images:\n",
        "    resized_image = cv2.resize(image, (new_width, new_height))\n",
        "    resized_images.append(resized_image)"
      ],
      "metadata": {
        "id": "_KvLirha2cux"
      },
      "id": "_KvLirha2cux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resized_images 리스트를 NumPy 배열로 변환\n",
        "resized_images_array = np.array(resized_images)\n",
        "\n",
        "# 변환된 NumPy 배열 출력\n",
        "print(resized_images_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGQVe-8y6NC_",
        "outputId": "678ed40d-b690-4804-9ddc-3fd0cb821a40"
      },
      "id": "TGQVe-8y6NC_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 200, 200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = resized_images_array.reshape(resized_images_array.shape[0], 200 * 200 * 3)"
      ],
      "metadata": {
        "id": "Kc3akT0O2qlE"
      },
      "id": "Kc3akT0O2qlE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels에 대한 코드\n",
        "num = len(images)\n",
        "labels = np.zeros(num)\n",
        "\n",
        "# 웜, 쿨의 데이터를 0과 1로 나눠 표시되도록\n",
        "labels[length:] = 1\n",
        "\n",
        "# 0이 쿨톤 1이 웜톤\n",
        "print(len(images))\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFgexRSm7Lyq",
        "outputId": "b9305f54-4e20-4479-f3b4-8ed1bcb42d56"
      },
      "id": "PFgexRSm7Lyq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7  # 훈련 세트 비율\n",
        "val_ratio = 0.2    # 검증 세트 비율\n",
        "train_data, train_labels, val_data, val_labels, test_data, test_labels = split_data(images, labels, train_ratio, val_ratio)\n",
        "print(\"train: \", train_data.shape)\n",
        "print(\"val: \", val_data.shape)\n",
        "print(\"test: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viEfOUkz2qe7",
        "outputId": "9b0059a9-ae0e-4a0d-be8f-2c5622dd3d5c"
      },
      "id": "viEfOUkz2qe7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 데이터 갯수:  100\n",
            "총 라벨 갯수:  100\n",
            "train:  (70, 120000)\n",
            "val:  (20, 120000)\n",
            "test:  (10, 120000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 여기서 라벨 개수가 2개가 나와야하는거 아닌가?"
      ],
      "metadata": {
        "id": "wu3HJqoeElIV"
      },
      "id": "wu3HJqoeElIV"
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 셋에서 가장 잘 동작하는 hyperparameter 들을 찾는다.\n",
        "validation_accuracies = []\n",
        "for k in [1, 3, 5, 10, 20, 25, 30]:\n",
        "\n",
        "    # 특정 k 값을 정해서 검증 데이터에 대해 평가할 때 사용한다.\n",
        "    nn = NearestNeighbor()\n",
        "    nn.train(train_data, train_labels)\n",
        "    # 여기서는 k를 input으로 받을 수 있도록 변형된 NearestNeighbor 클래스가 있다고 가정하자.\n",
        "    Yval_predict = nn.predict(val_data, k = k)\n",
        "    acc = np.mean(Yval_predict == val_labels)\n",
        "    print('accuracy: %f' % (acc,))\n",
        "\n",
        "    # 검증 셋에 대한 정확도를 저장해 놓는다.\n",
        "    validation_accuracies.append((k, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DQ0-8WB2qZP",
        "outputId": "1809b7db-1a2f-4d1c-c0f7-7551cf140e3c"
      },
      "id": "9DQ0-8WB2qZP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.600000\n",
            "accuracy: 0.550000\n",
            "accuracy: 0.400000\n",
            "accuracy: 0.400000\n",
            "accuracy: 0.600000\n",
            "accuracy: 0.500000\n",
            "accuracy: 0.550000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['웜톤', '쿨톤']\n",
        "\n",
        "# def personal_color(ima):\n",
        "  # img =\n",
        "\n",
        "def classify_image(image):\n",
        "    # Preprocess the image\n",
        "    image = image.reshape((1, 32 * 32 * 3)) / 255.0\n",
        "\n",
        "    # Load the trained model\n",
        "    model = keras.models.load_model('keras_cifar10_model.h5')\n",
        "\n",
        "    # Perform prediction\n",
        "    prediction = model.predict(image)\n",
        "    class_index = np.argmax(prediction)\n",
        "    class_name = class_names[class_index]\n",
        "\n",
        "    return class_name"
      ],
      "metadata": {
        "id": "_kxLbz6x78RI"
      },
      "id": "_kxLbz6x78RI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7a13d1",
      "metadata": {
        "id": "5f7a13d1"
      },
      "outputs": [],
      "source": [
        "# KNN 퍼스널 컬러 분류 함수 만들기\n",
        "\n",
        "def personal_color(img):\n",
        "    nn = NearestNeighbor()\n",
        "    X_train = train_data  # Training data features\n",
        "    y_train = train_labels  # Training data labels\n",
        "    nn.train(X_train, y_train)\n",
        "\n",
        "    prediction = nn.predict(img, k = 5)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a8c41a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "4a8c41a5",
        "outputId": "664eafd5-4d0e-4ade-87a4-fbae407415fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-73227275436d>:7: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Image(shape=(200, 200)),\n",
            "<ipython-input-27-73227275436d>:7: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Image(shape=(200, 200)),\n",
            "<ipython-input-27-73227275436d>:8: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n",
            "<ipython-input-27-73227275436d>:8: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5b5480191a0b24c172.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5b5480191a0b24c172.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# gradio로 시각화? 웹 구현\n",
        "import gradio as gr\n",
        "\n",
        "classification = gr.Interface(fn=personal_color,\n",
        "                              # inputs=\"image\",\n",
        "                              # outputs=\"label\",\n",
        "                              inputs=gr.inputs.Image(shape=(200, 200)),\n",
        "                              outputs=gr.outputs.Label(num_top_classes=2))\n",
        "\n",
        "\n",
        "classification.launch(share=True,\n",
        "                      server_name = \"0.0.0.0\",\n",
        "                      server_port = 8081)\n",
        "                      # auth = (\"noname\", \"passwdl\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def personal_color(img):\n",
        "    # Preprocess the new image if needed\n",
        "\n",
        "    # Load the pre-trained model or create a new instance of NearestNeighbor\n",
        "    nn = NearestNeighbor()\n",
        "\n",
        "    # Load the training data\n",
        "    X_train = train_data  # Training data features\n",
        "    y_train = train_labels  # Training data labels\n",
        "\n",
        "    # Train the model\n",
        "    nn.train(X_train, y_train)\n",
        "\n",
        "    # Convert the new image to the appropriate format (e.g., N x D)\n",
        "    X_test = img # Preprocess the new image to match the training data format\n",
        "\n",
        "    # Set the value of k for k-nearest neighbors\n",
        "    k = 5  # Define the value of k\n",
        "\n",
        "    # Predict the label of the new image\n",
        "    predicted_label = nn.predict(X_test, k)\n",
        "\n",
        "    # Return the predicted label\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "NtK0cHowz7CH"
      },
      "id": "NtK0cHowz7CH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_1 = '/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/sticker_app/images/서현진1.jpg'\n",
        "personal_color(img_1) ## 시도해보았으나 에러뜸. 함수를  같다."
      ],
      "metadata": {
        "id": "0fecAEpo3SZz"
      },
      "id": "0fecAEpo3SZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "classification = gr.Interface(fn=personal_color,\n",
        "                              inputs=gr.inputs.Image(shape=(200, 200)),\n",
        "                              outputs=gr.outputs.Label(num_top_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_qWEtwoz6z9",
        "outputId": "866bb8a2-6e21-4b2d-ef9c-a4dcc5a9ee92"
      },
      "id": "0_qWEtwoz6z9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-444224c19c17>:4: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  inputs=gr.inputs.Image(shape=(200, 200)),\n",
            "<ipython-input-30-444224c19c17>:4: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  inputs=gr.inputs.Image(shape=(200, 200)),\n",
            "<ipython-input-30-444224c19c17>:5: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n",
            "<ipython-input-30-444224c19c17>:5: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
            "  outputs=gr.outputs.Label(num_top_classes=2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classification.launch(share=True)"
      ],
      "metadata": {
        "id": "fiqdS7j3z6wu"
      },
      "id": "fiqdS7j3z6wu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN : Skin detection을 적용한 앱 구현(2)"
      ],
      "metadata": {
        "id": "byGXeSzV5umd"
      },
      "id": "byGXeSzV5umd"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ro6fgQld53U6"
      },
      "id": "ro6fgQld53U6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Skin_Detection(img_path):\n",
        "\n",
        "  #Open a simple image\n",
        "  img=cv2.imread(img_path)\n",
        "\n",
        "  #converting from gbr to YCbCr color space\n",
        "  img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "  #skin color range for hsv color space\n",
        "  YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135))\n",
        "  YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
        "\n",
        "  YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
        "  YCrCb_skin_detected = cv2.bitwise_and(img, img, mask=YCrCb_mask)  # img와 YCrCb_mask를 입력으로 사용하여 원본 이미지에서 피부 픽셀만 추출\n",
        "\n",
        "  return img_YCrCb, YCrCb_mask"
      ],
      "metadata": {
        "id": "8CglCJUP53Sh"
      },
      "id": "8CglCJUP53Sh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skin 좌표 추출, YCrCb 픽셀값 추출\n",
        "def coordinate_extraction(mask, img):\n",
        "  skin = np.argwhere(mask == 255) # mask의 픽셀값이 255인 skin부분의 좌표 추출 : (rgb로 따지는 거야? ybbcr말고?)\n",
        "\n",
        "  pixel_values = [] # YCbCr 픽셀값 저장을 위한 리스트\n",
        "\n",
        "  for index in skin:\n",
        "    y, x = index  #일반적으로 생각하는 가로 x, 세로 y로 표현하기 위해 위치 바꿈\n",
        "    #print(f\"x: {x}, y: {y}\") # skin 범위 좌표값 출력(스압주의)\n",
        "    pixel_value = img[y, x]\n",
        "    pixel_values.append(pixel_value)\n",
        "\n",
        "  for coord, pixel_value in zip(skin, pixel_values): # skin부분의 좌표값과 픽셀값 출력을 위한 함수\n",
        "    x, y = coord\n",
        "    # print(f\"Coordinate: ({x}, {y}), Pixel Value: {pixel_value}\")\n",
        "\n",
        "  return pixel_values"
      ],
      "metadata": {
        "id": "WXNJievc53Pq"
      },
      "id": "WXNJievc53Pq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 픽셀의 평균값 구하기\n",
        "def pixel_means(pixel_values):\n",
        "  # 열 별로 원소들을 더하기\n",
        "  column_sums = np.sum(pixel_values, axis=0)\n",
        "\n",
        "  # pixel_values를 NumPy 배열로 변환\n",
        "  pixel_values = np.array(pixel_values)\n",
        "\n",
        "  # 열 별로 평균 계산하기\n",
        "  column_means = column_sums / pixel_values.shape[0]\n",
        "\n",
        "  return column_means"
      ],
      "metadata": {
        "id": "sa8Tf8AB53Nv"
      },
      "id": "sa8Tf8AB53Nv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dict(dir_path):\n",
        "  file_list = os.listdir(dir_path)\n",
        "\n",
        "  img_list = []\n",
        "  result_list = []\n",
        "\n",
        "  for file in file_list:\n",
        "    img_path = os.path.join(dir_path, file)\n",
        "    if os.path.isdir(img_path):  # 만약 디렉토리인 경우, 무시하고 다음 파일로 넘어감\n",
        "      continue\n",
        "    file_name = file\n",
        "    file_name = os.path.splitext(file_name)[0] # 파일 이름과 확장자 분리\n",
        "    img_YCrCb,YCrCb_mask = Skin_Detection(img_path)\n",
        "    img_list.append([img_YCrCb, YCrCb_mask]) # 그림 show()를 위한 용도\n",
        "\n",
        "    # YCrCb\n",
        "    YCrCb_pixel_values = coordinate_extraction(YCrCb_mask, img_YCrCb)\n",
        "    YCrCb_pixel_means = pixel_means(YCrCb_pixel_values)\n",
        "    #print(YCrCb_pixel_means)\n",
        "\n",
        "    result_list.append(YCrCb_pixel_means)\n",
        "\n",
        "  return result_list"
      ],
      "metadata": {
        "id": "v01PwN5B53Kq"
      },
      "id": "v01PwN5B53Kq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/쿨\"  # 디렉토리 경로\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜\"  # 디렉토리 경로"
      ],
      "metadata": {
        "id": "xre4wdg853FF"
      },
      "id": "xre4wdg853FF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cool_result  = get_dict(path) # 1분"
      ],
      "metadata": {
        "id": "h1chKc8w53Cj"
      },
      "id": "h1chKc8w53Cj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warm_result  = get_dict(path2) # 1분"
      ],
      "metadata": {
        "id": "cvLXt6Wb6JoW"
      },
      "id": "cvLXt6Wb6JoW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.concatenate((cool_result, warm_result), axis=0)\n",
        "print(images) #스압 조큼 있음"
      ],
      "metadata": {
        "id": "Fc3Ojm3z6Jla"
      },
      "id": "Fc3Ojm3z6Jla",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels에 대한 코드\n",
        "num = len(images)\n",
        "labels = np.zeros(num)\n",
        "\n",
        "# 처음 50개의 요소를 1로 변경\n",
        "labels[50:] = 1\n",
        "\n",
        "# 0이 쿨톤 1이 웜톤\n",
        "print(len(images))\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3nmTYSf6Jik",
        "outputId": "8f42b239-ab57-4cad-c5f0-18afe4748d87"
      },
      "id": "v3nmTYSf6Jik",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, val, test 분리\n",
        "\n",
        "def split_data(data, labels, train_ratio, val_ratio):\n",
        "    # 데이터 개수 확인\n",
        "    num_examples = len(data)\n",
        "    num_lables = len(labels)\n",
        "    print(\"총 데이터 갯수: \", len(data))\n",
        "    print(\"총 라벨 갯수: \", len(labels))\n",
        "\n",
        "    # 인덱스를 섞은 배열 생성\n",
        "    shuffled_indices = np.random.permutation(num)\n",
        "\n",
        "    # 훈련 세트, 검증 세트, 테스트 세트 크기 계산\n",
        "    train_size = int(num_examples * train_ratio)\n",
        "    val_size = int(num_examples * val_ratio)\n",
        "    test_size = num_examples - train_size - val_size\n",
        "\n",
        "    # 데이터와 레이블을 분할하여 저장할 변수 초기화\n",
        "    train_data = np.zeros((train_size, *data.shape[1:]))\n",
        "    train_labels = np.zeros((train_size, *labels.shape[1:]))\n",
        "    val_data = np.zeros((val_size, *data.shape[1:]))\n",
        "    val_labels = np.zeros((val_size, *labels.shape[1:]))\n",
        "    test_data = np.zeros((test_size, *data.shape[1:]))\n",
        "    test_labels = np.zeros((test_size, *labels.shape[1:]))\n",
        "\n",
        "    # 데이터와 레이블을 섞은 인덱스를 기반으로 분할\n",
        "    train_indices = shuffled_indices[:train_size]\n",
        "    val_indices = shuffled_indices[train_size:train_size+val_size]\n",
        "    test_indices = shuffled_indices[train_size+val_size:]\n",
        "\n",
        "    train_data = data[train_indices]\n",
        "    train_labels = labels[train_indices]\n",
        "    val_data = data[val_indices]\n",
        "    val_labels = labels[val_indices]\n",
        "    test_data = data[test_indices]\n",
        "    test_labels = labels[test_indices]\n",
        "\n",
        "    return train_data, train_labels, val_data, val_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "t0cCY-Z32qh-"
      },
      "id": "t0cCY-Z32qh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7  # 훈련 세트 비율\n",
        "val_ratio = 0.2    # 검증 세트 비율\n",
        "train_data, train_labels, val_data, val_labels, test_data, test_labels = split_data(images, labels, train_ratio, val_ratio)\n",
        "print(\"train: \", train_data.shape)\n",
        "print(\"val: \", val_data.shape)\n",
        "print(\"test: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYtlqNBA6Jew",
        "outputId": "b4fd1236-4089-483d-b1a4-21dec34e0054"
      },
      "id": "IYtlqNBA6Jew",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 데이터 갯수:  100\n",
            "총 라벨 갯수:  100\n",
            "train:  (70, 3)\n",
            "val:  (20, 3)\n",
            "test:  (10, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NearestNeighbor(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, X, y):\n",
        "        \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
        "        # nearest neighbor 분류기는 단순히 모든 학습 데이터를 기억해둔다.\n",
        "        self.Xtr = X\n",
        "        self.ytr = y\n",
        "\n",
        "    def predict(self, X, k):\n",
        "        \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
        "        num_test = X.shape[0]\n",
        "        # 출력 type과 입력 type이 같게 되도록 확인해준다.\n",
        "        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
        "\n",
        "    # loop over all test rows\n",
        "        for i in range(num_test):\n",
        "        # i번째 테스트 이미지와 가장 가까운 학습 이미지를\n",
        "        # L1 거리(절대값 차의 총합)를 이용하여 찾는다.\n",
        "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
        "            #distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))\n",
        "            #min_index = np.argmin(distances) # 가장 작은 distance를 갖는 인덱스를 찾는다.\n",
        "            #pred[i] = self.ytr[min_index] # 가장 가까운 이웃의 라벨로 예측\n",
        "\n",
        "            indices = np.argsort(distances)  # 거리가 작은 순서대로 인덱스 정렬\n",
        "            k_nearest_labels = self.ytr[indices[:k]]  # k개의 가장 가까운 이웃의 라벨\n",
        "            unique, counts = np.unique(k_nearest_labels, return_counts=True)\n",
        "            Ypred[i] = unique[np.argmax(counts)]  # 가장 많은 투표를 받은 라벨로 예측\n",
        "        return Ypred"
      ],
      "metadata": {
        "id": "AD97VPpb2qcV"
      },
      "id": "AD97VPpb2qcV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 셋에서 가장 잘 동작하는 hyperparameter 들을 찾는다.\n",
        "validation_accuracies = []\n",
        "for k in [5, 10, 20, 25, 30]:\n",
        "\n",
        "    # 특정 k 값을 정해서 검증 데이터에 대해 평가할 때 사용한다.\n",
        "    nn = NearestNeighbor()\n",
        "    nn.train(train_data, train_labels)\n",
        "    # 여기서는 k를 input으로 받을 수 있도록 변형된 NearestNeighbor 클래스가 있다고 가정하자.\n",
        "    Yval_predict = nn.predict(val_data, k = k)\n",
        "    acc = np.mean(Yval_predict == val_labels)\n",
        "    print('accuracy: %f' % (acc,))\n",
        "\n",
        "    # 검증 셋에 대한 정확도를 저장해 놓는다.\n",
        "    validation_accuracies.append((k, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcBIR3Er6JbB",
        "outputId": "e2dba708-bb6b-47f1-88eb-725390543d43"
      },
      "id": "YcBIR3Er6JbB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.650000\n",
            "accuracy: 0.650000\n",
            "accuracy: 0.550000\n",
            "accuracy: 0.450000\n",
            "accuracy: 0.450000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제 본격적인 최고 25개 85% / 정확도 45%~85%정도 나오는듯\n",
        "print(validation_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2_cHHAj6JVd",
        "outputId": "1622db95-c879-4d8b-ad94-0b6372e72b29"
      },
      "id": "v2_cHHAj6JVd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(5, 0.65), (10, 0.65), (20, 0.55), (25, 0.45), (30, 0.45)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXMq0IQOJOXc",
        "outputId": "2055112a-4517-4618-c5c5-05a43924a017"
      },
      "id": "HXMq0IQOJOXc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- k가 마지막 숫자인30으로 설정되어 있기 때문에 밑에서는 위에서 본 최고 성능을 내는 숫자로 다시 지정해주어야 한다"
      ],
      "metadata": {
        "id": "TqOsdo6OW-mf"
      },
      "id": "TqOsdo6OW-mf"
    },
    {
      "cell_type": "code",
      "source": [
        "Ytest_predict = nn.predict(test_data, k = 10)\n",
        "print(Ytest_predict)\n",
        "print(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee1Qx19u6Ro4",
        "outputId": "07abdc2e-b2b2-4c40-c50e-59a2f45e648d"
      },
      "id": "ee1Qx19u6Ro4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
            "[1. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def personal_color_app(img):\n",
        "  Ytest_predict = nn.predict(img, k = k)\n",
        "  return test_labels"
      ],
      "metadata": {
        "id": "c74UHC41LE2M"
      },
      "id": "c74UHC41LE2M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = /content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜/공효진.jpg\n",
        "personal_color_app(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "vqtwjOLOL37i",
        "outputId": "876f526e-842c-4dcd-bc2e-ac1a1b5937e9"
      },
      "id": "vqtwjOLOL37i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-2af00c052df0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    img = /content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜/공효진.jpg\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- FAIL. 다시..."
      ],
      "metadata": {
        "id": "MnJZ7O_jXMvh"
      },
      "id": "MnJZ7O_jXMvh"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "classification = gr.Interface(fn=personal_color_app,\n",
        "                              inputs='image',\n",
        "                              outputs='label')"
      ],
      "metadata": {
        "id": "2kf_1bpKJ3A1"
      },
      "id": "2kf_1bpKJ3A1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification.launch(share=True)"
      ],
      "metadata": {
        "id": "inPTygt76Ri2"
      },
      "id": "inPTygt76Ri2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  skin detection을 이용한 KNN 모델 및 앱 구현\n",
        "\n",
        "1. KNN 모델 구현\n",
        "2. 클래스 이름 정해서 나누기\n",
        "3. 각 클래스가 반환되도록 함수 만들기\n",
        "4. gradio에 연결"
      ],
      "metadata": {
        "id": "ceNyynuMMRG5"
      },
      "id": "ceNyynuMMRG5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 불러오기 및 데이터 로드"
      ],
      "metadata": {
        "id": "qDMeo107NyJf"
      },
      "id": "qDMeo107NyJf"
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IOhOnAkBMZJ9"
      },
      "id": "IOhOnAkBMZJ9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_directory(directory_path):\n",
        "    image_paths = glob.glob(directory_path + '/*.jpg')  # 디렉토리 내의 모든 jpg 파일 경로 찾기\n",
        "    #image_paths.extend(glob.glob(directory_path + '/)*.png')  # 디렉토리 내의 모든 png 파일 경로 추가 오류남\n",
        "    image_paths.extend(glob.glob(directory_path + '/*.jpeg'))  # 디렉토리 내의 모든 jpeg 파일 경로 추가\n",
        "    image_paths.extend(glob.glob(directory_path + '/*.jfif'))  # 디렉토리 내의 모든 jfif 파일 경로 추가\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path)\n",
        "        image_np = np.array(image)\n",
        "        images.append(image_np)\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "rExEInEjMZDr"
      },
      "id": "rExEInEjMZDr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 이미지 불러오기\n",
        "directory_path = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/쿨\"  # 디렉토리 경로\n",
        "directory_path2 = \"/content/drive/MyDrive/Colab Notebooks/AIFFEL/Data/four_seasons/웜\"  # 디렉토리 경로\n",
        "images = load_images_from_directory(directory_path)\n",
        "images2 = load_images_from_directory(directory_path2)\n",
        "\n",
        "length = len(images)\n",
        "print(length)\n",
        "print(len(images2))\n",
        "\n",
        "# 이미지 리스트 합치기\n",
        "images = np.concatenate((images, images2), axis=0)\n",
        "print(len(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0u5vLPKMZAU",
        "outputId": "67a872d9-d09b-4480-c249-290ff807193c"
      },
      "id": "d0u5vLPKMZAU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n",
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리 및 train, val, test 데이터 나누기"
      ],
      "metadata": {
        "id": "qs2IyPkgN1J7"
      },
      "id": "qs2IyPkgN1J7"
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터를 train+val 데이터를 추가하기\n",
        "\n",
        "def split_data(data, labels, train_ratio, val_ratio):\n",
        "    # 데이터 개수 확인\n",
        "    num_examples = len(data)\n",
        "    num_lables = len(labels)\n",
        "    print(\"총 데이터 갯수: \", len(data))\n",
        "    print(\"총 라벨 갯수: \", len(labels))\n",
        "\n",
        "    # 인덱스를 섞은 배열 생성\n",
        "    shuffled_indices = np.random.permutation(num)\n",
        "\n",
        "    # 훈련 세트, 검증 세트, 테스트 세트 크기 계산\n",
        "    train_size = int(num_examples * train_ratio)\n",
        "    val_size = int(num_examples * val_ratio)\n",
        "    test_size = num_examples - train_size - val_size\n",
        "\n",
        "    # 데이터와 레이블을 분할하여 저장할 변수 초기화\n",
        "    train_data = np.zeros((train_size, *data.shape[1:]))\n",
        "    train_labels = np.zeros((train_size, *labels.shape[1:]))\n",
        "    val_data = np.zeros((val_size, *data.shape[1:]))\n",
        "    val_labels = np.zeros((val_size, *labels.shape[1:]))\n",
        "    test_data = np.zeros((test_size, *data.shape[1:]))\n",
        "    test_labels = np.zeros((test_size, *labels.shape[1:]))\n",
        "\n",
        "    # 데이터와 레이블을 섞은 인덱스를 기반으로 분할\n",
        "    train_indices = shuffled_indices[:train_size]\n",
        "    val_indices = shuffled_indices[train_size:train_size+val_size]\n",
        "    test_indices = shuffled_indices[train_size+val_size:]\n",
        "\n",
        "    train_data = data[train_indices]\n",
        "    train_labels = labels[train_indices]\n",
        "    val_data = data[val_indices]\n",
        "    val_labels = labels[val_indices]\n",
        "    test_data = data[test_indices]\n",
        "    test_labels = labels[test_indices]\n",
        "    train_full_data = np.concatente(train_data, val_data)\n",
        "    train_full_labels = np.concatenate(train_labels, val_labels)\n",
        "\n",
        "    return train_full_data, train_full_labels, train_data, train_labels, val_data, val_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "gyAweT7eOdbc"
      },
      "id": "gyAweT7eOdbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7  # 훈련 세트 비율\n",
        "val_ratio = 0.2    # 검증 세트 비율\n",
        "train_data, train_labels, val_data, val_labels, test_data, test_labels = split_data(images, labels, train_ratio, val_ratio)\n",
        "\n",
        "print('full_train: ', train_full_data)\n",
        "print(\"train: \", train_data.shape)\n",
        "print(\"val: \", val_data.shape)\n",
        "print(\"test: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "zIOGZgDjOdXV",
        "outputId": "309770b4-cde3-49c6-a40e-b09ea3930715"
      },
      "id": "zIOGZgDjOdXV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e47c8a26ab25>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m  \u001b[0;31m# 훈련 세트 비율\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m    \u001b[0;31m# 검증 세트 비율\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_train: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_full_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['웜톤', '쿨톤']"
      ],
      "metadata": {
        "id": "zVdWUOqlO1zw"
      },
      "id": "zVdWUOqlO1zw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_full_labels[:2])"
      ],
      "metadata": {
        "id": "9qhiBOBbO7RZ"
      },
      "id": "9qhiBOBbO7RZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C_CXfr1-N1AL"
      },
      "id": "C_CXfr1-N1AL"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnAgBi5QMY8-"
      },
      "id": "PnAgBi5QMY8-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn7YwvNgMY44"
      },
      "id": "Vn7YwvNgMY44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r8nXIbMxMY1m"
      },
      "id": "r8nXIbMxMY1m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNAOZZG7MYx0"
      },
      "id": "zNAOZZG7MYx0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jc-_mNtSMYuP"
      },
      "id": "jc-_mNtSMYuP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGmjsahBMYpq"
      },
      "id": "DGmjsahBMYpq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKzqbzhEMYgY"
      },
      "id": "rKzqbzhEMYgY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a60ed55a",
      "metadata": {
        "id": "a60ed55a"
      },
      "source": [
        "# Reference\n",
        "\n",
        "- 분류 모델 공식 홈페이지 데모 버전 (https://www.gradio.app/guides/image-classification-in-tensorflow)\n",
        "- 코드로 압축 풀기 (https://zeuskwon-ds.tistory.com/52)\n",
        "- 모폴로지 연산 (https://bkshin.tistory.com/entry/OpenCV-19-%EB%AA%A8%ED%8F%B4%EB%A1%9C%EC%A7%80Morphology-%EC%97%B0%EC%82%B0-%EC%B9%A8%EC%8B%9D-%ED%8C%BD%EC%B0%BD-%EC%97%B4%EB%A6%BC-%EB%8B%AB%ED%9E%98-%EA%B7%B8%EB%A0%88%EB%94%94%EC%96%B8%ED%8A%B8-%ED%83%91%ED%96%87-%EB%B8%94%EB%9E%99%ED%96%87)\n",
        "-"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
