{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9daf44c1",
   "metadata": {},
   "source": [
    "# 프로젝트: 퍼스널 컬러 진단 - ResNet50\n",
    "\n",
    "## 데이터\n",
    "일반인 웜 490장, 쿨 186장  \n",
    "\n",
    "## 목표: ResNet50에 퍼스널 컬러 진단 분류하기  \n",
    "참고 링크: https://wjunsea.tistory.com/99  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f615f",
   "metadata": {},
   "source": [
    "## (1) 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5d3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb55e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오는 함수\n",
    "def load_images_from_directory(directory_path):\n",
    "    image_paths = glob.glob(directory_path + '/*.jpg')  # 디렉토리 내의 모든 jpg 파일 경로 찾기\n",
    "    image_paths.extend(glob.glob(directory_path + '/*.jpeg'))  # 디렉토리 내의 모든 jpeg 파일 경로 추가\n",
    "    image_paths = glob.glob(directory_path + '/*.JPG')  # 디렉토리 내의 모든 JPG 파일 경로 찾기\n",
    "\n",
    "    images = []\n",
    "    i = 0\n",
    "    for image_path in image_paths:\n",
    "        if i == 150:\n",
    "            break\n",
    "        image = Image.open(image_path)\n",
    "        image_np = np.array(image)\n",
    "        images.append(image_np)\n",
    "        i += 1\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d74894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# 모든 이미지 불러오기\n",
    "directory_path = \"/aiffel//aiffel/project/first-repository/data/four_seasons/train_warm_1\"  # 디렉토리 경로\n",
    "directory_path2 = \"/aiffel/aiffel/project/first-repository/data/four_seasons/train_cool_1/cool_1\"  # 디렉토리 경로\n",
    "images = load_images_from_directory(directory_path)\n",
    "images2 = load_images_from_directory(directory_path2)\n",
    "\n",
    "length = len(images)\n",
    "print(length)\n",
    "print(len(images2))\n",
    "\n",
    "# 이미지 리스트 합치기\n",
    "images = np.concatenate((images, images2), axis=0)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aefc0e",
   "metadata": {},
   "source": [
    "## (2) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc5644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image):\n",
    "    # 이미지 크기 조절\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    # 이미지를 [0, 1] 범위로 정규화\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "images = np.array([preprocess_image(image) for image in images])\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba87ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "(300, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# labels에 대한 코드\n",
    "num = len(images)\n",
    "labels = np.zeros(num)\n",
    "\n",
    "# 뒤쪽의 50개의 요소를 1로 변경\n",
    "labels[length:] = 1\n",
    "\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# 0이 웜톤 1이 쿨톤\n",
    "print(len(images))\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 증강을 위한 ImageDataGenerator 생성\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 이미지 증강 적용하여 증강된 이미지를 배치로 생성\n",
    "augmented_images = datagen.flow(images, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033d29c",
   "metadata": {},
   "source": [
    "## (3) trian, val 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416cf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (210, 224, 224, 3)\n",
      "y_train:  (210, 2)\n",
      "x_val:  (90, 224, 224, 3)\n",
      "y_val:  (90, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(images,\n",
    "                                                  labels,\n",
    "                                                  test_size=0.3,\n",
    "                                                  random_state=55)\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_val: \", x_val.shape)\n",
    "print(\"y_val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88c3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 텐서로 변환\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_val = tf.convert_to_tensor(x_val, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e09c4",
   "metadata": {},
   "source": [
    "## (4) 모델 정의 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d0ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          131200      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,827,490\n",
      "Trainable params: 25,774,370\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "\n",
    "# ResNet-50 모델 불러오기\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = GlobalAveragePooling2D()(resnet50.output) # flatten과 비슷한 역할(각 필터의 평균값을 리턴)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "# 새로운 모델 정의\n",
    "model = tf.keras.models.Model(inputs=resnet50.input, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d2b32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 콜백 생성\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.000001)\n",
    "\n",
    "# 모델을 평가 모드로 설정 (학습이 아닌 추론용으로 사용할 때 필요)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49e5ef",
   "metadata": {},
   "source": [
    "## (5) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc6f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 53s 373ms/step - loss: 1.1285 - accuracy: 0.5190 - val_loss: 8.9192 - val_accuracy: 0.4778\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.7796 - accuracy: 0.5667 - val_loss: 5537.3276 - val_accuracy: 0.4778\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.8099 - accuracy: 0.5667 - val_loss: 1627.2162 - val_accuracy: 0.4778\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.7258 - accuracy: 0.6000 - val_loss: 277.2650 - val_accuracy: 0.4778\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.6492 - accuracy: 0.6714 - val_loss: 46.7197 - val_accuracy: 0.4778\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.6496 - accuracy: 0.7143 - val_loss: 4.6177 - val_accuracy: 0.4778\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.6461 - accuracy: 0.7095 - val_loss: 0.6927 - val_accuracy: 0.5222\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6370 - accuracy: 0.7571 - val_loss: 0.6943 - val_accuracy: 0.5222\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6401 - accuracy: 0.6714 - val_loss: 0.6942 - val_accuracy: 0.5222\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6149 - accuracy: 0.7333 - val_loss: 0.6915 - val_accuracy: 0.5222\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.5806 - accuracy: 0.7381 - val_loss: 0.6923 - val_accuracy: 0.5222\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.5515 - accuracy: 0.7714 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.5876 - accuracy: 0.7000 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.5492 - accuracy: 0.7381 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.5708 - accuracy: 0.7619 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.5566 - accuracy: 0.7524 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.5575 - accuracy: 0.7905 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5703 - accuracy: 0.7762 - val_loss: 0.6926 - val_accuracy: 0.5222\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.6080 - accuracy: 0.7095 - val_loss: 0.6924 - val_accuracy: 0.5222\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5592 - accuracy: 0.7524 - val_loss: 0.6924 - val_accuracy: 0.5222\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5139 - accuracy: 0.8286 - val_loss: 0.6924 - val_accuracy: 0.5222\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.5584 - accuracy: 0.8000 - val_loss: 0.6923 - val_accuracy: 0.5222\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.5593 - accuracy: 0.7905 - val_loss: 0.6923 - val_accuracy: 0.5222\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.5875 - accuracy: 0.7333 - val_loss: 0.6923 - val_accuracy: 0.5222\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5562 - accuracy: 0.7476 - val_loss: 0.6922 - val_accuracy: 0.5222\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5546 - accuracy: 0.7762 - val_loss: 0.6922 - val_accuracy: 0.5222\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.5421 - accuracy: 0.7952 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.5556 - accuracy: 0.7905 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.5806 - accuracy: 0.7524 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.5756 - accuracy: 0.7524 - val_loss: 0.6920 - val_accuracy: 0.5222\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=30,\n",
    "                    validation_data=(x_val, y_val), \n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9adbb2",
   "metadata": {},
   "source": [
    "## (6) 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ab142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)\n",
    "pred_class = np.argmax(pred, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352d24c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0\n",
      " 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1]\n",
      "[[0.5048852  0.492829  ]\n",
      " [0.50505495 0.49252343]\n",
      " [0.5062992  0.48969007]\n",
      " [0.50621295 0.48977616]\n",
      " [0.5052818  0.4920864 ]\n",
      " [0.5062965  0.48972937]\n",
      " [0.5050225  0.4926064 ]\n",
      " [0.505006   0.49260905]\n",
      " [0.5064042  0.4895639 ]\n",
      " [0.50501066 0.49260095]\n",
      " [0.5050915  0.492492  ]\n",
      " [0.5060822  0.49006262]\n",
      " [0.50491714 0.4928664 ]\n",
      " [0.5058395  0.4905223 ]\n",
      " [0.5050995  0.4924714 ]\n",
      " [0.5050488  0.4925986 ]\n",
      " [0.5051314  0.49243867]\n",
      " [0.5054453  0.4916465 ]\n",
      " [0.5050879  0.49245155]\n",
      " [0.50501037 0.49266794]\n",
      " [0.5053655  0.49185422]\n",
      " [0.5055821  0.4912495 ]\n",
      " [0.5050331  0.49258748]\n",
      " [0.5054532  0.49165744]\n",
      " [0.5062919  0.48969698]\n",
      " [0.5063422  0.4896202 ]\n",
      " [0.50617564 0.48990637]\n",
      " [0.50628966 0.48971   ]\n",
      " [0.5053357  0.4919432 ]\n",
      " [0.50519717 0.49231163]\n",
      " [0.5049109  0.4928589 ]\n",
      " [0.505253   0.49213585]\n",
      " [0.505097   0.49249822]\n",
      " [0.5051349  0.49242324]\n",
      " [0.5060505  0.49007523]\n",
      " [0.50519747 0.49228227]\n",
      " [0.50500494 0.49270892]\n",
      " [0.5050081  0.49266344]\n",
      " [0.5064181  0.48949665]\n",
      " [0.5056659  0.4910379 ]\n",
      " [0.50506073 0.49257597]\n",
      " [0.5061145  0.49001214]\n",
      " [0.5055564  0.49141273]\n",
      " [0.5050487  0.49255434]\n",
      " [0.50643456 0.4894777 ]\n",
      " [0.50501674 0.49265686]\n",
      " [0.5060956  0.4900559 ]\n",
      " [0.5050811  0.49249932]\n",
      " [0.50504315 0.49260646]\n",
      " [0.5055458  0.49132776]\n",
      " [0.5057567  0.49091884]\n",
      " [0.5050234  0.49259725]\n",
      " [0.50534123 0.49191046]\n",
      " [0.5064648  0.4893885 ]\n",
      " [0.504964   0.49276027]\n",
      " [0.505743   0.4907062 ]\n",
      " [0.50522304 0.49219653]\n",
      " [0.5051615  0.49232203]\n",
      " [0.5050338  0.49258688]\n",
      " [0.5053792  0.49197635]\n",
      " [0.5050198  0.49268225]\n",
      " [0.5056836  0.4909544 ]\n",
      " [0.50504684 0.49261054]\n",
      " [0.5061255  0.48995095]\n",
      " [0.5053738  0.49182567]\n",
      " [0.5058342  0.49068493]\n",
      " [0.5051484  0.49243027]\n",
      " [0.5060653  0.4900812 ]\n",
      " [0.5049968  0.49265292]\n",
      " [0.50517553 0.49233133]\n",
      " [0.50518006 0.49230233]\n",
      " [0.5060689  0.4900051 ]\n",
      " [0.50522655 0.49237484]\n",
      " [0.50510824 0.4924434 ]\n",
      " [0.505011   0.4926462 ]\n",
      " [0.50504506 0.49257347]\n",
      " [0.5050329  0.4926082 ]\n",
      " [0.505281   0.49199557]\n",
      " [0.5050612  0.49263093]\n",
      " [0.505932   0.49044824]\n",
      " [0.50500464 0.49267063]\n",
      " [0.5053601  0.49193266]\n",
      " [0.5048911  0.49282762]\n",
      " [0.5053439  0.49196285]\n",
      " [0.5053693  0.4918425 ]\n",
      " [0.50518334 0.49233386]\n",
      " [0.5050453  0.49258256]\n",
      " [0.5054267  0.49167708]\n",
      " [0.5054857  0.4915854 ]\n",
      " [0.5052864  0.49210346]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_class)\n",
    "print(y_val)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d218fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.522222\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(pred_class == y_val)\n",
    "print('accuracy: %f' % (acc,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56125732",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확도 시각화\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 손실값 시각화\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc14d2",
   "metadata": {},
   "source": [
    "## (7) TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97030305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\"웜톤\", \"쿨톤\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86256a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 불러오기 (낱개 버전)\n",
    "test_path = \"/aiffel/aiffel/project/first-repository/data/four_seasons/TEST/박은빈.jpg\"\n",
    "x_test = Image.open(test_path)\n",
    "x_test = np.array(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "# 배열의 크기 변환\n",
    "x_test = x_test.reshape((1, x_test.shape[0], x_test.shape[1], 3))\n",
    "print(\"변환된 배열 크기:\", x_test.shape)\n",
    "\n",
    "# 전처리(resize, 정규화)\n",
    "x_test = preprocess_image(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "# 만약 앱구현과 연결된다면 저장된 모델을 다시 돌릴 필요없이 저장된 최적의 모델을 사용하도록 수정해야함\n",
    "# test\n",
    "pred = model.predict(x_test)\n",
    "pred_class = np.argmax(pred, axis=1)\n",
    "print(\"당신은\", class_name[int(pred_class)], \"입니다~!\")\n",
    "print(\"웜톤일 확률: \", np.round(pred[:, 0], 3))\n",
    "print(\"쿨톤일 확률: \", np.round(pred[:, 1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcccd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089f431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
